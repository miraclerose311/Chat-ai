{"key": "web_search:2022 USA national auto sales by brand", "value": "[{'title': 'Full-Year 2022 National Auto Sales By Brand', 'link': 'https://www.carpro.com/blog/full-year-2022-national-auto-sales-by-brand', 'snippet': 'Jan 12, 2023 ... Full-Year 2022 National Auto Sales By Brand ; 1. Toyota, 1,849,751 ; 2. Ford, 1,767,439 ; 3. Chevrolet, 1,502,389 ; 4. Honda, 881,201\\xa0...'}, {'title': '2022 U.S. Auto Sales Figures by Brand | GCBC', 'link': 'https://www.goodcarbadcar.net/2022-us-vehicle-sales-figures-by-brand/', 'snippet': '2022 US Vehicle Sales Figures By Brand. Comprehensive data tables and charts for automotive sales in the United States. Home.'}, {'title': 'USA - Flash report, Automotive sales volume, 2023 - MarkLines ...', 'link': 'https://www.marklines.com/en/statistics/flash_sales/automotive-sales-in-usa-by-month', 'snippet': 'Light vehicle seasonally adjusted annualized sales (SAAR) for February 2023 was 15.19 million units versus 13.96 million units one year ago. With its vehicle\\xa0...'}, {'title': 'August U.S. auto sales: Toyota, Honda skid again; Ford, Hyundai ...', 'link': 'https://www.autonews.com/sales/august-us-auto-sales-toyota-honda-skid-again-ford-hyundai-kia-post-double-digit-august-gains', 'snippet': 'Sep 1, 2022 ... LMC Automotive on Friday slashed its outlook for 2022 sales to 13.8 million from 14.3 million. S&P Global Mobility last week reduced its\\xa0...'}, {'title': 'NADA Releases Third Quarter 2022 U.S. Auto Sales Analysis | NADA', 'link': 'https://www.nada.org/nada/press-releases/nada-releases-third-quarter-2022-us-auto-sales-analysis', 'snippet': 'Oct 12, 2022 ... The third quarter of 2022 closed with a new light-vehicle sales totaling a quarterly average SAAR of 13.3 million units, down slightly from a\\xa0...'}, {'title': 'Hybrid-Electric, Plug-in Hybrid-Electric and Electric Vehicle Sales ...', 'link': 'https://www.bts.gov/content/gasoline-hybrid-and-electric-vehicle-sales', 'snippet': '21, 2022. Publications: National Transportation Statistics Table 1-19.'}, {'title': 'NADA Issues Analysis of 2022 Auto Sales and 2023 Sales Forecast ...', 'link': 'https://www.nada.org/nada/press-releases/nada-issues-analysis-2022-auto-sales-and-2023-sales-forecast', 'snippet': 'Jan 11, 2023 ... In 2023, NADA anticipates new-vehicle sales of 14.6 million units \u2013 an increase of 6.6% from 2022. At the macro level, inflation has begun to\\xa0...'}, {'title': 'Light Duty Electric Drive Vehicles Monthly Sales Updates | Argonne ...', 'link': 'https://www.anl.gov/esia/light-duty-electric-drive-vehicles-monthly-sales-updates', 'snippet': '... United States, up 68.1% from the sales in May 2022. PEVs captured 8.36% of ... Vehicle Emissions,\u201d Argonne National Laboratory, Lemont, IL USA, ANL/ESD-22\\xa0...'}, {'title': 'Market Beat | NADA', 'link': 'https://www.nada.org/nada/research-and-data/market-beat', 'snippet': '... U.S. new light vehicle sales; it replaces the NADA Monthly Sales Recap ... 2022 Archives. December NADA Market Beat: 2022 New Light-Vehicle Sales top\\xa0...'}, {'title': 'Cox Automotive Forecast: August U.S. Auto Sales Languish at Slow ...', 'link': 'https://www.coxautoinc.com/news/cox-automotive-forecast-august-2022-u-s-auto-sales-forecast/', 'snippet': 'Aug 25, 2022 ... August 2022 numbers illustrate just how difficult forecasting new-vehicle sales has become. On the one hand, the national daily sales rate\\xa0...'}]"}
{"key": "Given a Query and a list of Google Search Results, return the link\nfrom a reputable website which contains the data set to answer the question. {''}\nQuery:2022 USA national auto sales by brand\nGoogle Search Results: \n```\n[{'title': 'Full-Year 2022 National Auto Sales By Brand', 'link': 'https://www.carpro.com/blog/full-year-2022-national-auto-sales-by-brand', 'snippet': 'Jan 12, 2023 ... Full-Year 2022 National Auto Sales By Brand ; 1. Toyota, 1,849,751 ; 2. Ford, 1,767,439 ; 3. Chevrolet, 1,502,389 ; 4. Honda, 881,201\\xa0...'}, {'title': '2022 U.S. Auto Sales Figures by Brand | GCBC', 'link': 'https://www.goodcarbadcar.net/2022-us-vehicle-sales-figures-by-brand/', 'snippet': '2022 US Vehicle Sales Figures By Brand. Comprehensive data tables and charts for automotive sales in the United States. Home.'}, {'title': 'USA - Flash report, Automotive sales volume, 2023 - MarkLines ...', 'link': 'https://www.marklines.com/en/statistics/flash_sales/automotive-sales-in-usa-by-month', 'snippet': 'Light vehicle seasonally adjusted annualized sales (SAAR) for February 2023 was 15.19 million units versus 13.96 million units one year ago. With its vehicle\\xa0...'}, {'title': 'August U.S. auto sales: Toyota, Honda skid again; Ford, Hyundai ...', 'link': 'https://www.autonews.com/sales/august-us-auto-sales-toyota-honda-skid-again-ford-hyundai-kia-post-double-digit-august-gains', 'snippet': 'Sep 1, 2022 ... LMC Automotive on Friday slashed its outlook for 2022 sales to 13.8 million from 14.3 million. S&P Global Mobility last week reduced its\\xa0...'}, {'title': 'NADA Releases Third Quarter 2022 U.S. Auto Sales Analysis | NADA', 'link': 'https://www.nada.org/nada/press-releases/nada-releases-third-quarter-2022-us-auto-sales-analysis', 'snippet': 'Oct 12, 2022 ... The third quarter of 2022 closed with a new light-vehicle sales totaling a quarterly average SAAR of 13.3 million units, down slightly from a\\xa0...'}, {'title': 'Hybrid-Electric, Plug-in Hybrid-Electric and Electric Vehicle Sales ...', 'link': 'https://www.bts.gov/content/gasoline-hybrid-and-electric-vehicle-sales', 'snippet': '21, 2022. Publications: National Transportation Statistics Table 1-19.'}, {'title': 'NADA Issues Analysis of 2022 Auto Sales and 2023 Sales Forecast ...', 'link': 'https://www.nada.org/nada/press-releases/nada-issues-analysis-2022-auto-sales-and-2023-sales-forecast', 'snippet': 'Jan 11, 2023 ... In 2023, NADA anticipates new-vehicle sales of 14.6 million units \u2013 an increase of 6.6% from 2022. At the macro level, inflation has begun to\\xa0...'}, {'title': 'Light Duty Electric Drive Vehicles Monthly Sales Updates | Argonne ...', 'link': 'https://www.anl.gov/esia/light-duty-electric-drive-vehicles-monthly-sales-updates', 'snippet': '... United States, up 68.1% from the sales in May 2022. PEVs captured 8.36% of ... Vehicle Emissions,\u201d Argonne National Laboratory, Lemont, IL USA, ANL/ESD-22\\xa0...'}, {'title': 'Market Beat | NADA', 'link': 'https://www.nada.org/nada/research-and-data/market-beat', 'snippet': '... U.S. new light vehicle sales; it replaces the NADA Monthly Sales Recap ... 2022 Archives. December NADA Market Beat: 2022 New Light-Vehicle Sales top\\xa0...'}, {'title': 'Cox Automotive Forecast: August U.S. Auto Sales Languish at Slow ...', 'link': 'https://www.coxautoinc.com/news/cox-automotive-forecast-august-2022-u-s-auto-sales-forecast/', 'snippet': 'Aug 25, 2022 ... August 2022 numbers illustrate just how difficult forecasting new-vehicle sales has become. On the one hand, the national daily sales rate\\xa0...'}]\n```\nThe answer MUST contain the url link only\n", "value": "https://www.carpro.com/blog/full-year-2022-national-auto-sales-by-brand"}
{"key": "Given the following question:\n```\n2022 USA national auto sales by brand\n```\nI got the following answer from a web page:\n```\nFull-Year 2022 National Auto Sales By Brand <img src=\"https://data.adxcel-ec2.com/pixel/?ad_log=referer&amp;action=lead&amp;pixid=b719b86c-f9d4-4c28-a8a8-135a5ff2099d\" width=\"1\" height=\"1\" border=\"0\"> Search Create Account Login CarPro You have a friend. Listen Live Buy a Car Find a CarPro Friend Find a Car Sell Your Car Car Buying Resources Car Reviews FAQs News Laura's Auto News Radio Show Radio Schedule Radio Blog Dealer True Stories CarPro Radio Show Podcast Driving N Heels Podcast CarPro Radio Show Newsletter Listen Live Menu News, Auto Sales Full-Year 2022 National Auto Sales By Brand Written by Jerry Reynolds January 12, 2023 Share: Facebook Twitter LinkedIn Email It was a challenging year for the auto industry, primarily due to the microchip shortages, and certainly rising interest rates did not help. There was also a noticeable lack of incentives from the automakers, and lease deals were not nearly as good as in years past. December showed some sparks of life for many car companies, as sales rose 7.2%, but not enough to put the sales numbers over the 14 million mark, making 2022 sales the lowest since 2011. General Motors regained the #1 sales leadership spot, wrestling it away from Toyota, which was #1 in 2021. Ford F-Series trucks retained the title of #1 truck in America for 46 straight years and the #1 selling vehicle overall for 41 straight years. Here are your winners and losers by brand for the full year of 2022 and how the numbers fared versus the year of 2021: Brand 2022 U.S. Sales VS 2021 1. Toyota 1,849,751 Down 9% 2. Ford 1,767,439 Down 2% 3. Chevrolet 1,502,389 Up 6% 4. Honda 881,201 Down 33% 5. Hyundai 724,265 Down 2% 6. Kia 693,549 Down 1% 7. Jeep 684,612 Down 12% 8. Nissan 682,731 Down 25% 9. Subaru 556,581 Down 5% 10. Ram Trucks 545,194 Down 16% 11. GMC 517,649 Up 7% 12. Mercedes-Benz 350,949 Up 7% 13. BMW 332,388 Down 1% 14. Volkswagen 301,069 Down 20% 15. Mazda 294,908 Down 11% 16. Lexus 258,704 Down 15% 17. Dodge 190,793 Down 12% 18. Audi 186,875 Down 5% 19. Cadillac 134,726 Up 14% 20. Chrysler 112,713 Down 2% 21. Buick 103,519 Down 42% 22. Acura 102,306 Down 35% 23. Volvo 102,038 Down 16% 24. Mitsubishi 102,037 Down 16% 25. Lincoln 83,486 Down 4% 26. Porsche 70,065 Flat 27. Genesis 56,410 Up 14% 28. INFINITI 46,619 Down 20% 29. MINI 29,504 Down 1% 30. Alfa Romeo 12,845 Down 30% 31. Maserati 6,413 Down 10% 32. Bentley 3,975 FLAT 33. Lamborghini 3,134 Up 3% 34. Fiat 915 Down 61% 35. McLaren 840 Down 35% 36. Rolls-Royce 460 Up 7% Note: Jaguar and Land Rover have not reported 2022 sales. Also, the all-electric makes like Tesla, Lucid, Karma, and Polestar do not report sales, only how many vehicles were produced, but that is not a reflection of actual sales since we don\u2019t know how many were built, but not sold. Photo Credit: Toyota. Share: Facebook Twitter LinkedIn Email Jerry Reynolds From police officer to top-selling Ford dealer to on-air car expert, Jerry helms our weekly radio show. Since selling his dealerships in 2006, Jerry has pursued his top three passions: helping consumers have a great car buying experience, supporting the military and first responders, being a loyal servant to his dog! While Jerry admits to hitting the pedal to the metal on test drives, it's all the service of finding out just how fast he can go from 0 to 60. Share On Facebook Share On Twitter Recent Posts Crime Wave: Two Vehicles Stolen Every Minute Read Post Summer Road Trip Checklist For Your Car Read Post CarPro Follow us on Facebook Follow us on Twitter Follow us on Youtube Follow us on Instagram Find a CarPro Friend Find a Car Radio Show About Us Why CarPro FAQs News Car Reviews Laura's Auto News Radio Show Newsletter Website Help Email the CarPro Media Company Inquiry Become a Radio Partner Become a Certified CarPro \u00a92023 CarPro Privacy Policy Terms Of Use Accessibility Statement CarPro requires our Certified Dealers to meet certain customer service requirements in accordance with our Certification Process and Agreement. CarPro does not broker, sell, or lease vehicles. All vehicles shown on this website are offered for sale by licensed motor vehicle dealers, unless where otherwise noted. Used vehicles are subject to prior sale. By accessing this website, you agree to the CarPro Terms of Service and Privacy Policy. We strive to update our website in a timely manner however CarPro cannot guarantee that the inventory shown will be available at the dealership. We are not responsible for typographical and other errors, including data transmissions or software errors that may appear on the site. If the posted price, incentive, offer or other service is incorrect due to typographical or other error we will only be responsible for honoring the correct price, incentive or offer. We make every effort to provide you the most accurate, up-to-the-minute information however when you are ready to purchase products or services, it is your responsibility to verify with us that all details listed are accurate. Prices include all applicable rebates.\n```\nNow help me write a SQL query to store the answer into a temp view.\nHere is an example of how to store data into a temp view:\n```\nCREATE OR REPLACE TEMP VIEW movies AS SELECT * FROM VALUES('Citizen Kane', 1941), ('Schindler's List', 1993) AS v1(title, year)\n```\n\nThe answer MUST contain query only.\n", "value": "CREATE OR REPLACE TEMP VIEW auto_sales_2022 AS SELECT * FROM VALUES\n('Toyota', 1849751, -9),\n('Ford', 1767439, -2),\n('Chevrolet', 1502389, 6),\n('Honda', 881201, -33),\n('Hyundai', 724265, -2),\n('Kia', 693549, -1),\n('Jeep', 684612, -12),\n('Nissan', 682731, -25),\n('Subaru', 556581, -5),\n('Ram Trucks', 545194, -16),\n('GMC', 517649, 7),\n('Mercedes-Benz', 350949, 7),\n('BMW', 332388, -1),\n('Volkswagen', 301069, -20),\n('Mazda', 294908, -11),\n('Lexus', 258704, -15),\n('Dodge', 190793, -12),\n('Audi', 186875, -5),\n('Cadillac', 134726, 14),\n('Chrysler', 112713, -2),\n('Buick', 103519, -42),\n('Acura', 102306, -35),\n('Volvo', 102038, -16),\n('Mitsubishi', 102037, -16),\n('Lincoln', 83486, -4),\n('Porsche', 70065, 0),\n('Genesis', 56410, 14),\n('INFINITI', 46619, -20),\n('MINI', 29504, -1),\n('Alfa Romeo', 12845, -30),\n('Maserati', 6413, -10),\n('Bentley', 3975, 0),\n('Lamborghini', 3134, 3),\n('Fiat', 915, -61),\n('McLaren', 840, -35),\n('Rolls-Royce', 460, 7)\nAS v1(brand, us_sales, sales_change_percentage)"}
{"key": "You are an Apache Spark SQL expert, who can summary what a dataframe retrieves. Given an analyzed \nquery plan of a dataframe, you will \n1. convert the dataframe to SQL query. Note that an explain output contains plan \nnodes separated by `\\n`. Each plan node has its own expressions and expression ids. \n2. summary what the sql query retrieves. \n\n\n\nanalyzed_plan: \nGlobalLimit 100\n    +- LocalLimit 100\n       +- Sort [d_year ASC NULLS FIRST, sum_agg DESC NULLS LAST, brand_id ASC NULLS FIRST], true\n          +- Aggregate [d_year, i_brand, i_brand_id], [d_year, i_brand_id AS brand_id, i_brand AS brand, sum(ss_ext_sales_price) AS sum_agg]\n             +- Filter (((d_date_sk = ss_sold_date_sk) AND (ss_item_sk = i_item_sk)) AND ((i_manufact_id = 128) AND (d_moy = 11)))\n                +- Join Inner\n                   :- Join Inner\n                   :  :- SubqueryAlias dt\n                   :  :  +- SubqueryAlias spark_catalog.tpcds_sf1_delta.date_dim\n                   :  :     +- Relation spark_catalog.tpcds_sf1_delta.date_dim[d_date_sk,d_date_id,d_date,d_month_seq,d_week_seq,d_quarter_seq,d_year,d_dow,d_moy,d_dom,d_qoy,d_fy_year,d_fy_quarter_seq,d_fy_week_seq,d_day_name,d_quarter_name,d_holiday,d_weekend,d_following_holiday,d_first_dom,d_last_dom,d_same_day_ly,d_same_day_lq,d_current_day,... 4 more fields] parquet\n                   :  +- SubqueryAlias spark_catalog.tpcds_sf1_delta.store_sales\n                   :     +- Relation spark_catalog.tpcds_sf1_delta.store_sales[ss_sold_date_sk,ss_sold_time_sk,ss_item_sk,ss_customer_sk,ss_cdemo_sk,ss_hdemo_sk,ss_addr_sk,ss_store_sk,ss_promo_sk,ss_ticket_numberL,ss_quantity,ss_wholesale_cost,ss_list_price,ss_sales_price,ss_ext_discount_amt,ss_ext_sales_price,ss_ext_wholesale_cost,ss_ext_list_price,ss_ext_tax,ss_coupon_amt,ss_net_paid,ss_net_paid_inc_tax,ss_net_profit] parquet\n                   +- SubqueryAlias spark_catalog.tpcds_sf1_delta.item\n                      +- Relation spark_catalog.tpcds_sf1_delta.item[i_item_sk,i_item_id,i_rec_start_date,i_rec_end_date,i_item_desc,i_current_price,i_wholesale_cost,i_brand_id,i_brand,i_class_id,i_class,i_category_id,i_category,i_manufact_id,i_manufact,i_size,i_formulation,i_color,i_units,i_container,i_manager_id,i_product_name] parquet\n\nexplain: \nThe analyzed plan can be translated into the following SQL query:\n```sql\nSELECT\n  dt.d_year,\n  item.i_brand_id brand_id,\n  item.i_brand brand,\n  SUM(ss_ext_sales_price) sum_agg\nFROM date_dim dt, store_sales, item\nWHERE dt.d_date_sk = store_sales.ss_sold_date_sk\n  AND store_sales.ss_item_sk = item.i_item_sk\n  AND item.i_manufact_id = 128\n  AND dt.d_moy = 11\nGROUP BY dt.d_year, item.i_brand, item.i_brand_id\nORDER BY dt.d_year, sum_agg DESC, brand_id\nLIMIT 100\n```\nIn summary, this dataframe is retrieving the top 100 brands (specifically of items manufactured by manufacturer with id 128) with the highest total sales price for each year in the month of November. It presents the results sorted by year, total sales (in descending order), and brand id.\n\n\n\nanalyzed_plan: SubqueryAlias auto_sales_2022\n+- View (`auto_sales_2022`, [brand,us_sales,sales_change_percentage])\n   +- Project [cast(brand as string) AS brand, cast(us_sales as int) AS us_sales, cast(sales_change_percentage as int) AS sales_change_percentage]\n      +- Project [brand, us_sales, sales_change_percentage]\n         +- SubqueryAlias v1\n            +- LocalRelation [brand, us_sales, sales_change_percentage]\n\nexplain:", "value": "The analyzed plan can be translated into the following SQL query:\n```sql\nCREATE VIEW auto_sales_2022 AS\nSELECT\n  CAST(brand AS STRING) AS brand,\n  CAST(us_sales AS INT) AS us_sales,\n  CAST(sales_change_percentage AS INT) AS sales_change_percentage\nFROM v1\n```\nIn summary, this dataframe is creating a view called `auto_sales_2022` with columns `brand`, `us_sales`, and `sales_change_percentage`. The view is based on the local relation `v1` and casts the columns to their respective data types (string for brand, int for us_sales, and int for sales_change_percentage)."}
{"key": "\nYou are an Apache Spark SQL expert programmer.\n\nGiven a pyspark dataframe `df`.\n\nThe output columns of `df`:\nbrand: string\nus_sales: int\nsales_change_percentage: int\n\nAnd an explanation of `df`: The analyzed plan can be translated into the following SQL query:\n```sql\nCREATE VIEW auto_sales_2022 AS\nSELECT\n  CAST(brand AS STRING) AS brand,\n  CAST(us_sales AS INT) AS us_sales,\n  CAST(sales_change_percentage AS INT) AS sales_change_percentage\nFROM v1\n```\nIn summary, this dataframe is creating a view called `auto_sales_2022` with columns `brand`, `us_sales`, and `sales_change_percentage`. The view is based on the local relation `v1` and casts the columns to their respective data types (string for brand, int for us_sales, and int for sales_change_percentage).\n\nWrite python code to visualize the result of `df` using plotly.\nYour code should NOT include the method 'append'. \nThere is no need to install any package with pip. \nDisplay the plot directly, instead of saving into an HTML.\nEnsure that your code is correct.\n\n", "value": "To visualize the result of `df` using Plotly, you can follow these steps:\n\n1. Convert the PySpark DataFrame to a Pandas DataFrame.\n2. Create a Plotly figure using the Pandas DataFrame.\n3. Display the plot directly.\n\nHere's the code to achieve this:\n\n```python\nimport pandas as pd\nimport plotly.express as px\n\n# Convert the PySpark DataFrame to a Pandas DataFrame\npdf = df.toPandas()\n\n# Create a Plotly figure using the Pandas DataFrame\nfig = px.bar(pdf, x='brand', y='us_sales', text='sales_change_percentage',\n             labels={'brand': 'Brand', 'us_sales': 'US Sales', 'sales_change_percentage': 'Sales Change Percentage'},\n             title='Auto Sales 2022')\n\n# Customize the plot\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n\n# Display the plot directly\nfig.show()\n```\n\nThis code will create a bar chart with the `brand` on the x-axis, `us_sales` on the y-axis, and the `sales_change_percentage` displayed as text above each bar. The plot will be displayed directly without saving it to an HTML file."}
{"key": "\nYou are an Apache Spark SQL expert programmer.\n\nGiven a pyspark dataframe `df`.\n\nThe output columns of `df`:\nbrand: string\nus_sales: int\nsales_change_percentage: int\n\nAnd an explanation of `df`: The analyzed plan can be translated into the following SQL query:\n```sql\nCREATE VIEW auto_sales_2022 AS\nSELECT\n  CAST(brand AS STRING) AS brand,\n  CAST(us_sales AS INT) AS us_sales,\n  CAST(sales_change_percentage AS INT) AS sales_change_percentage\nFROM v1\n```\nIn summary, this dataframe is creating a view called `auto_sales_2022` with columns `brand`, `us_sales`, and `sales_change_percentage`. The view is based on the local relation `v1` and casts the columns to their respective data types (string for brand, int for us_sales, and int for sales_change_percentage).\n\nWrite python code to visualize the result of `df` using plotly.\nYour code should NOT include the method 'append'. \nThere is no need to install any package with pip. \nDisplay the plot directly, instead of saving into an HTML.\nEnsure that your code is correct.\nThe purpose of the plot: pie chart for US sales market shares, show the top 5 brands and the sum of others\n", "value": "To visualize the result of `df` using Plotly, you can follow these steps:\n\n1. Import the necessary libraries\n2. Convert the PySpark DataFrame to a Pandas DataFrame\n3. Calculate the top 5 brands and the sum of others\n4. Create a pie chart using Plotly\n5. Display the plot\n\nHere's the code:\n\n```python\nimport plotly.graph_objs as go\nimport pandas as pd\n\n# Convert the PySpark DataFrame to a Pandas DataFrame\npdf = df.toPandas()\n\n# Calculate the top 5 brands and the sum of others\ntop_5_brands = pdf.nlargest(5, 'us_sales')\nother_brands_sum = pdf.loc[~pdf.index.isin(top_5_brands.index), 'us_sales'].sum()\n\n# Add the sum of others to the top 5 brands DataFrame\nother_brands_row = pd.DataFrame({'brand': ['Others'], 'us_sales': [other_brands_sum]})\ntop_5_brands_with_others = pd.concat([top_5_brands, other_brands_row], ignore_index=True)\n\n# Create a pie chart using Plotly\nfig = go.Figure(data=[go.Pie(labels=top_5_brands_with_others['brand'],\n                             values=top_5_brands_with_others['us_sales'],\n                             hole=.3)])\n\n# Customize the plot\nfig.update_layout(title='US Sales Market Shares: Top 5 Brands and Others',\n                  annotations=[dict(text='Top 5 Brands', x=0.5, y=0.5, font_size=20, showarrow=False)])\n\n# Display the plot\nfig.show()\n```\n\nThis code will display a pie chart of the US sales market shares, showing the top 5 brands and the sum of others."}
{"key": "\nGiven a Spark temp view `temp_view_for_transform` with the following columns:\n```\nbrand: string\nus_sales: int\nsales_change_percentage: int\n```\nWrite a Spark SQL query to retrieve: top brand with the highest growth\nThe answer MUST contain query only.\n", "value": "SELECT brand, sales_change_percentage\nFROM temp_view_for_transform\nORDER BY sales_change_percentage DESC\nLIMIT 1"}
{"key": "You are an Apache Spark SQL expert, who can summary what a dataframe retrieves. Given an analyzed \nquery plan of a dataframe, you will \n1. convert the dataframe to SQL query. Note that an explain output contains plan \nnodes separated by `\\n`. Each plan node has its own expressions and expression ids. \n2. summary what the sql query retrieves. \n\n\n\nanalyzed_plan: \nGlobalLimit 100\n    +- LocalLimit 100\n       +- Sort [d_year ASC NULLS FIRST, sum_agg DESC NULLS LAST, brand_id ASC NULLS FIRST], true\n          +- Aggregate [d_year, i_brand, i_brand_id], [d_year, i_brand_id AS brand_id, i_brand AS brand, sum(ss_ext_sales_price) AS sum_agg]\n             +- Filter (((d_date_sk = ss_sold_date_sk) AND (ss_item_sk = i_item_sk)) AND ((i_manufact_id = 128) AND (d_moy = 11)))\n                +- Join Inner\n                   :- Join Inner\n                   :  :- SubqueryAlias dt\n                   :  :  +- SubqueryAlias spark_catalog.tpcds_sf1_delta.date_dim\n                   :  :     +- Relation spark_catalog.tpcds_sf1_delta.date_dim[d_date_sk,d_date_id,d_date,d_month_seq,d_week_seq,d_quarter_seq,d_year,d_dow,d_moy,d_dom,d_qoy,d_fy_year,d_fy_quarter_seq,d_fy_week_seq,d_day_name,d_quarter_name,d_holiday,d_weekend,d_following_holiday,d_first_dom,d_last_dom,d_same_day_ly,d_same_day_lq,d_current_day,... 4 more fields] parquet\n                   :  +- SubqueryAlias spark_catalog.tpcds_sf1_delta.store_sales\n                   :     +- Relation spark_catalog.tpcds_sf1_delta.store_sales[ss_sold_date_sk,ss_sold_time_sk,ss_item_sk,ss_customer_sk,ss_cdemo_sk,ss_hdemo_sk,ss_addr_sk,ss_store_sk,ss_promo_sk,ss_ticket_numberL,ss_quantity,ss_wholesale_cost,ss_list_price,ss_sales_price,ss_ext_discount_amt,ss_ext_sales_price,ss_ext_wholesale_cost,ss_ext_list_price,ss_ext_tax,ss_coupon_amt,ss_net_paid,ss_net_paid_inc_tax,ss_net_profit] parquet\n                   +- SubqueryAlias spark_catalog.tpcds_sf1_delta.item\n                      +- Relation spark_catalog.tpcds_sf1_delta.item[i_item_sk,i_item_id,i_rec_start_date,i_rec_end_date,i_item_desc,i_current_price,i_wholesale_cost,i_brand_id,i_brand,i_class_id,i_class,i_category_id,i_category,i_manufact_id,i_manufact,i_size,i_formulation,i_color,i_units,i_container,i_manager_id,i_product_name] parquet\n\nexplain: \nThe analyzed plan can be translated into the following SQL query:\n```sql\nSELECT\n  dt.d_year,\n  item.i_brand_id brand_id,\n  item.i_brand brand,\n  SUM(ss_ext_sales_price) sum_agg\nFROM date_dim dt, store_sales, item\nWHERE dt.d_date_sk = store_sales.ss_sold_date_sk\n  AND store_sales.ss_item_sk = item.i_item_sk\n  AND item.i_manufact_id = 128\n  AND dt.d_moy = 11\nGROUP BY dt.d_year, item.i_brand, item.i_brand_id\nORDER BY dt.d_year, sum_agg DESC, brand_id\nLIMIT 100\n```\nIn summary, this dataframe is retrieving the top 100 brands (specifically of items manufactured by manufacturer with id 128) with the highest total sales price for each year in the month of November. It presents the results sorted by year, total sales (in descending order), and brand id.\n\n\n\nanalyzed_plan: GlobalLimit 1\n+- LocalLimit 1\n   +- Sort [sales_change_percentage DESC NULLS LAST], true\n      +- Project [brand, sales_change_percentage]\n         +- SubqueryAlias temp_view_for_transform\n            +- View (`temp_view_for_transform`, [brand,us_sales,sales_change_percentage])\n               +- SubqueryAlias auto_sales_2022\n                  +- View (`auto_sales_2022`, [brand,us_sales,sales_change_percentage])\n                     +- Project [cast(brand as string) AS brand, cast(us_sales as int) AS us_sales, cast(sales_change_percentage as int) AS sales_change_percentage]\n                        +- Project [brand, us_sales, sales_change_percentage]\n                           +- SubqueryAlias v1\n                              +- LocalRelation [brand, us_sales, sales_change_percentage]\n\nexplain:", "value": "The analyzed plan can be translated into the following SQL query:\n```sql\nSELECT\n  brand,\n  sales_change_percentage\nFROM temp_view_for_transform\nORDER BY sales_change_percentage DESC\nLIMIT 1\n```\nIn summary, this dataframe is retrieving the brand with the highest sales change percentage from the `temp_view_for_transform` view. The result will contain the brand name and its corresponding sales change percentage."}
{"key": "\nGiven 1) a PySpark dataframe, df, and 2) a description of expected properties, desc,\ngenerate a Python function to test whether the given dataframe satisfies the expected properties.\nYour generated function should take 1 parameter, df, and the return type should be a boolean.\nYou will call the function, passing in df as the parameter, and return the output (True/False).\n\nIn total, your output must follow the format below, exactly (no explanation words):\n1. function definition f, in Python\n2. 1 blank new line\n3. Call f on df and assign the result to a variable, result: result = name_of_f(df)\n\nInclude any necessary import statements INSIDE the function definition.\nFor example:\ndef gen_random():\n    import random\n    return random.randint(0, 10)\n\nFor example:\nInput:\ndf = DataFrame[name: string, age: int]\ndesc = \"expect 5 columns\"\n\nOutput:\n\"def has_5_columns(df) -> bool:\n    # Get the number of columns in the DataFrame\n    num_columns = len(df.columns)\n\n    # Check if the number of columns is equal to 5\n    if num_columns == 5:\n        return True\n    else:\n        return False\n\nresult = has_5_columns(df)\"\n\nHere is your input df: DataFrame[brand: string, sales_change_percentage: int]\nHere is your input description: expect sales change percentage to be between -100 to 100\n", "value": "def check_sales_change_percentage(df) -> bool:\n    from pyspark.sql.functions import col\n\n    # Filter the DataFrame to only include rows where sales_change_percentage is between -100 and 100\n    valid_rows = df.filter((col(\"sales_change_percentage\") >= -100) & (col(\"sales_change_percentage\") <= 100))\n\n    # Check if the number of valid rows is equal to the total number of rows in the DataFrame\n    if valid_rows.count() == df.count():\n        return True\n    else:\n        return False\n\nresult = check_sales_change_percentage(df)"}
{"key": "\nThis is the documentation for a PySpark user-defined function (udf): pyspark.sql.functions.udf\n\nA udf creates a deterministic, reusable function in Spark. It can take any data type as a parameter, \nand by default returns a String (although it can return any data type). \nThe point is to reuse a function on several dataframes and SQL functions.\n\nGiven 1) input arguments, 2) a description of the udf functionality,\n3) the udf return type, and 4) the udf function name, \ngenerate and return a callable udf.\n        \nReturn ONLY the callable resulting udf function (no explanation words). \nInclude any necessary import statements INSIDE the function definition.\nFor example:\ndef gen_random():\n    import random\n    return random.randint(0, 10)\n\n\n\ninput_args_types: (s: str)\ndesc: Convert string s to uppercase\nreturn_type: str\nudf_name: to_upper\noutput: \ndef to_upper(s) -> str:\n    if s is not None:\n        return s.upper()\n\n\n\n\ninput_args_types: (x: int)\ndesc: Add 1\nreturn_type: int\nudf_name: add_one\noutput: \ndef add_one(x) -> int:\n    if x is not None:\n        return x + 1\n\n\n\n\ninput_args_types: (brand: str, current_year_sale: int, sales_change_percentage: float)\ninput_desc: Calculate previous years sales from sales change percentage\nreturn_type: int\nudf_name: previous_years_sales\noutput:\n\n", "value": "def previous_years_sales(brand: str, current_year_sale: int, sales_change_percentage: float) -> int:\n    if brand is not None and current_year_sale is not None and sales_change_percentage is not None:\n        return int(current_year_sale / (1 + sales_change_percentage / 100))"}
