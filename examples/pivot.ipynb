{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Pivot Example with the Spark SQL ReAct Agent"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/07 20:48:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO: \u001B[0mThe pyspark.sql.connect.dataframe module could not be imported. This might be due to your PySpark version being below 3.4.\n"
     ]
    }
   ],
   "source": [
    "from pyspark_ai import SparkAI\n",
    "\n",
    "spark_ai = SparkAI(verbose=True)\n",
    "spark_ai.activate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Example 1: Bikes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "spark = spark_ai._spark\n",
    "# create a dataframe containing different bike product_catagory and product_count\n",
    "df = spark.createDataFrame(\n",
    "    [\n",
    "        (\"children bike\", 20),\n",
    "        (\"comfort bike\", 15),\n",
    "        (\"mountain bike\", 10),\n",
    "        (\"electric bike\", 5),\n",
    "        (\"road bike\", 3),\n",
    "        (\"cruisers bike\", 8)\n",
    "    ],\n",
    "    [\"product_category\", \"product_count\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO: \u001B[0mCreating temp view for the transform:\n",
      "df.createOrReplaceTempView(\u001B[33m\"\u001B[39;49;00m\u001B[33mspark_ai_temp_view_986ea9\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mThought: Spark SQL does not support dynamic pivot operations, which are required to transpose the table as requested. I should get all the distinct values of column product_category.\n",
      "Action: query_sql_db\n",
      "Action Input: \"SELECT DISTINCT product_category FROM spark_ai_temp_view_986ea9\"\u001B[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001B[36;1m\u001B[1;3m[('children bike',), ('comfort bike',), ('mountain bike',), ('electric bike',), ('road bike',), ('cruisers bike',)]\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3mI can write a query to pivot the table by product_category and sum the product_count for each category.\n",
      "Action: query_validation\n",
      "Action Input: SELECT * FROM spark_ai_temp_view_986ea9 PIVOT (SUM(product_count) FOR product_category IN ('children bike', 'comfort bike', 'mountain bike', 'electric bike', 'road bike', 'cruisers bike'))\u001B[0m\n",
      "Observation: \u001B[33;1m\u001B[1;3mOK\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3mI now know the final answer.\n",
      "Final Answer: SELECT * FROM spark_ai_temp_view_986ea9 PIVOT (SUM(product_count) FOR product_category IN ('children bike', 'comfort bike', 'mountain bike', 'electric bike', 'road bike', 'cruisers bike'))\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\u001B[92mINFO: \u001B[0mSQL query:\n",
      "\u001B[34mSELECT\u001B[39;49;00m\u001B[37m \u001B[39;49;00m*\u001B[37m \u001B[39;49;00m\u001B[34mFROM\u001B[39;49;00m\u001B[37m \u001B[39;49;00mspark_ai_temp_view_986ea9\u001B[37m \u001B[39;49;00mPIVOT\u001B[37m \u001B[39;49;00m(\u001B[34mSUM\u001B[39;49;00m(product_count)\u001B[37m \u001B[39;49;00m\u001B[34mFOR\u001B[39;49;00m\u001B[37m \u001B[39;49;00mproduct_category\u001B[37m \u001B[39;49;00m\u001B[34mIN\u001B[39;49;00m\u001B[37m \u001B[39;49;00m(\u001B[33m'children bike'\u001B[39;49;00m,\u001B[37m \u001B[39;49;00m\u001B[33m'comfort bike'\u001B[39;49;00m,\u001B[37m \u001B[39;49;00m\u001B[33m'mountain bike'\u001B[39;49;00m,\u001B[37m \u001B[39;49;00m\u001B[33m'electric bike'\u001B[39;49;00m,\u001B[37m \u001B[39;49;00m\u001B[33m'road bike'\u001B[39;49;00m,\u001B[37m \u001B[39;49;00m\u001B[33m'cruisers bike'\u001B[39;49;00m))\u001B[37m\u001B[39;49;00m\n",
      "\n",
      "+-------------+------------+-------------+-------------+---------+-------------+\n",
      "|children bike|comfort bike|mountain bike|electric bike|road bike|cruisers bike|\n",
      "+-------------+------------+-------------+-------------+---------+-------------+\n",
      "|           20|          15|           10|            5|        3|            8|\n",
      "+-------------+------------+-------------+-------------+---------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.ai.transform(\"pivot using product_category for product_count\").show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Example 2: Grades"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df2 = spark.createDataFrame(\n",
    "    [\n",
    "        (\"A\", \"English\", 45),\n",
    "        (\"A\", \"Maths\", 50),\n",
    "        (\"A\", \"Science\", 55),\n",
    "        (\"B\", \"English\", 75),\n",
    "        (\"B\", \"Maths\", 80),\n",
    "        (\"B\", \"Science\", 85),\n",
    "        (\"C\", \"English\", 90),\n",
    "        (\"C\", \"Maths\", 95),\n",
    "        (\"C\", \"Science\", 100),\n",
    "    ],\n",
    "    [\"Student\", \"Subject\", \"Marks\"]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[92mINFO: \u001B[0mCreating temp view for the transform:\n",
      "df.createOrReplaceTempView(\u001B[33m\"\u001B[39;49;00m\u001B[33mspark_ai_temp_view_833d28\u001B[39;49;00m\u001B[33m\"\u001B[39;49;00m)\u001B[37m\u001B[39;49;00m\n",
      "\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new AgentExecutor chain...\u001B[0m\n",
      "\u001B[32;1m\u001B[1;3mThought: Spark SQL does not support dynamic pivot operations, which are required to transpose the table as requested. I should get all the distinct values of column Subject.\n",
      "Action: query_sql_db\n",
      "Action Input: \"SELECT DISTINCT Subject FROM spark_ai_temp_view_833d28\"\u001B[0m\n",
      "Observation: \u001B[36;1m\u001B[1;3m[('English',), ('Maths',), ('Science',)]\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3mI can write a query to pivot the table by Subject and sum the Marks for each Student and Subject combination.\n",
      "Action: query_validation\n",
      "Action Input: SELECT * FROM spark_ai_temp_view_833d28 PIVOT (SUM(Marks) FOR Subject IN ('English', 'Maths', 'Science'))\u001B[0m\n",
      "Observation: \u001B[33;1m\u001B[1;3mOK\u001B[0m\n",
      "Thought:\u001B[32;1m\u001B[1;3mI now know the final answer.\n",
      "Final Answer: SELECT * FROM spark_ai_temp_view_833d28 PIVOT (SUM(Marks) FOR Subject IN ('English', 'Maths', 'Science'))\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\u001B[92mINFO: \u001B[0mSQL query:\n",
      "\u001B[34mSELECT\u001B[39;49;00m\u001B[37m \u001B[39;49;00m*\u001B[37m \u001B[39;49;00m\u001B[34mFROM\u001B[39;49;00m\u001B[37m \u001B[39;49;00mspark_ai_temp_view_833d28\u001B[37m \u001B[39;49;00mPIVOT\u001B[37m \u001B[39;49;00m(\u001B[34mSUM\u001B[39;49;00m(Marks)\u001B[37m \u001B[39;49;00m\u001B[34mFOR\u001B[39;49;00m\u001B[37m \u001B[39;49;00mSubject\u001B[37m \u001B[39;49;00m\u001B[34mIN\u001B[39;49;00m\u001B[37m \u001B[39;49;00m(\u001B[33m'English'\u001B[39;49;00m,\u001B[37m \u001B[39;49;00m\u001B[33m'Maths'\u001B[39;49;00m,\u001B[37m \u001B[39;49;00m\u001B[33m'Science'\u001B[39;49;00m))\u001B[37m\u001B[39;49;00m\n",
      "\n",
      "+-------+-------+-----+-------+\n",
      "|Student|English|Maths|Science|\n",
      "+-------+-------+-----+-------+\n",
      "|      B|     75|   80|     85|\n",
      "|      C|     90|   95|    100|\n",
      "|      A|     45|   50|     55|\n",
      "+-------+-------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.ai.transform(\"pivot using Subject for Marks\").show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
